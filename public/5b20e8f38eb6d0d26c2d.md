---
title: ネタとネタを足して2で割ったような記事
tags:
  - ネタ
  - word2vec
private: false
updated_at: '2023-02-19T19:33:34+09:00'
id: 5b20e8f38eb6d0d26c2d
organization_url_name: null
slide: false
---

# はじめに

「(.+)と(.+)を足して(\d+)で割った感じ」という表現がありますよね。しかし私は想像力に乏しいもので，そんなことを言われてもよくわかりません。よくわからないことはPythonに考えさせようという言葉があった気がするので(ない)，Pythonを使って言葉の平均を求めてみます。

## 基本方針

Word2vecという単語を足したり引いたりできる仕組みがあるのでそれを使います。
> パリ - フランス + 日本 = 京都

みたいなやつです[^1]。

[^1]: 実際のモデルで計算するとなぜか「東京」になります。不思議ですね。

加減算はできるらしいのですが割り算はよくわからないので，重みを付けて(例えば2単語であればそれぞれ0.5)全部足してあげます。

# 準備

## `gensim`

Word2vecをPythonで使うためのライブラリです
(本当はいろいろなことができるらしいのですが)

```
$ pip install --upgrade gensim
```

でOKです。

このライブラリの詳細を語ることはこの記事の目的ではないため詳細は省略します。
「gensim word2vec」などでググればたくさんの情報が出てきます。

## 学習済みモデル

Word2vecで遊ぶには学習済みモデルが必要になりますが，自前で用意するのは面倒なので公開されているものを利用させてもらいます。

- [Wikipedia Entity Vectors](https://github.com/singletongue/WikiEntVec/releases)
- [chiVe](https://github.com/WorksApplications/chiVe)

など各自で好きなものを選べばよいでしょう。だいたいGBオーダーなのでダウンロードに時間がかかります。
私はchiVeのv1.2 mc5を利用しました(単語数3,197,456)。

# やってみよう

単語を重み付きで足していく`add_words`を，[gensimのソースコード](https://github.com/RaRe-Technologies/gensim/blob/9ca0fe1adfc92d680c79ea0208d359e7703bf227/gensim/models/keyedvectors.py)を参考にしながら書いてみます。

```python
import gensim
from gensim import matutils
from numpy import dot, float32 as REAL, array
from sys import argv

MODEL_PATH = 'path/to/chive-1.2-mc5.kv'
model = gensim.models.KeyedVectors.load(MODEL_PATH)

def add_words(words, topn=10, clip_start=0, clip_end=None):
  clip_end = clip_end or len(model.vectors)

  all_keys, mean = set(), []
  for key, weight in words:
    mean.append(weight * model.get_vector(key, norm=True))
    all_keys.add(model.get_index(key))

  mean = matutils.unitvec(array(mean).mean(axis=0)).astype(REAL)
  dists = dot(model.vectors[clip_start:clip_end], mean) / model.norms[clip_start:clip_end]
  best = matutils.argsort(dists, topn=topn + len(all_keys), reverse=True)
  result = [
    (model.index_to_key[sim + clip_start], float(dists[sim]))
    for sim in best
    if (sim + clip_start) not in all_keys
  ]
  return result[:topn]

def main():
  args = argv[1:]
  n = len(args)
  words = [(w, 1/n) for w in args]
  res = add_words(words, topn=5)
  print(res)

if __name__ == '__main__':
  main()
```

## 実行例
Twitterで「足して2で割った」で検索して良さそうなものを探してみます。

### 眠気と目眩を足して2で割ったようなもの

最初から重めで申し訳ないですがやってみましょう

```
python wordsaverage.py 眠気 目眩
[('頭痛', 0.8051504492759705), ('吐き気', 0.7748003602027893), ('立ち眩み', 0.7618328332901001), ('睡魔', 0.7527350187301636), ('偏頭痛', 0.7508496642112732)]
```

見ているだけで頭が痛くなってきそうです。

### 東京と名古屋を足して2で割った感じ

```
python wordsaverage.py 東京 名古屋
[('大阪', 0.7572567462921143), ('福岡', 0.6995946764945984), ('愛知', 0.6942369341850281), ('横浜', 0.6731942892074585), ('札幌', 0.6508569717407227)]
```

各方面から怒られそうですが私は悪くないです。
(ちなみにツイートでは「豊橋」が「東京と名古屋を足して2で割った感じ」となっていました)

### ネタとネタを足しで2で割ったような記事

最後にこの記事のタイトルを食わせてみます。
※ 食わせた単語は結果から除外するようになっているため，「ネタ」と「ネタ」の平均をとっても「ネタ」にはなりません。

```
python wordsaverage.py ネタ ネタ
[('ハムスターネタ', 0.510507345199585), ('バトマスクエ', 0.4984256625175476), ('サリクシンカ', 0.49488064646720886), ('ネタバレガンガン', 0.48528173565864563), ('バドミントンネタ', 0.48384809494018555)]
```

……何使って学習してるんですかねこのモデルは

# さいごに

「○○と××を足しで2で割った感じ」と言われてもピンと来なかったときにお役に立てば幸いです。
